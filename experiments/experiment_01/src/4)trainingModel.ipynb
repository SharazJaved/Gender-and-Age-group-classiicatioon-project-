{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and buiilding the Gender and age group classification model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #1**: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from shutil import copyfile\n",
    "from scipy.stats import skew, kurtosis\n",
    "########################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "###########################################\n",
    "# This is a simple keras or tensorflow.keras library import for CNN \n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Input,Dropout,BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "\n",
    "##################################################\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "# This is a simple keras library import for CNN \n",
    "print(\"cv2_version:\",cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r saveMLmodelfile_name\n",
    "print(\"modelname:\", saveMLmodelfile_name)\n",
    "%store -r project_path\n",
    "print(\"project_path:\", project_path)\n",
    "%store -r result_filepath\n",
    "print(\"result_filepath:\", result_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #5**: preparation input face_image ( UTKFace_traindataset and UTKFace_traindataset)  of the  CNN  model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) normalization of image and paths for your train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for your dataset\n",
    "train_dirPath = project_path+\"/dataset/UTKFace_Processed_Traindataset\"\n",
    "val_dirPath= project_path+\"/dataset/UTKFace_Processed_Valdataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    # Convert to floating-point values #img_float = (image.astype(np.float32))\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    normalized_image = (image.astype(np.float32)) / 255.0\n",
    "\n",
    "    return normalized_image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) normalization of image of  UTKFace_traindataset and UTKFace_traindataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faceImage=[]\n",
    "\n",
    "for img in os.listdir(train_dirPath): \n",
    "    train_faceImage.append(normalize_image(np.array(cv2.imread(str(train_dirPath)+\"/\"+str(img),-1))))\n",
    "\n",
    "total_train_faceImage=len(train_faceImage)\n",
    "print(\"total no of train_faceImage: \", len(train_faceImage))\n",
    "print(\"sample of train_faceImage: \",train_faceImage[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_faceImage=[]\n",
    "\n",
    "for img in os.listdir(val_dirPath): \n",
    "    val_faceImage.append(normalize_image(np.array(cv2.imread(str(val_dirPath)+\"/\"+str(img),-1))))\n",
    "\n",
    "print(\"total of the val_faceImage: \", len(val_faceImage))\n",
    "print(\"sample of val_faceImage: \",val_faceImage[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #6**: preparation output label (gender and age group) of the  CNN  model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) extract the  gender and age annotation   form UTKFace_traindataset and UTKFace_valdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_age = []\n",
    "train_gender = [] \n",
    "\n",
    "for img in os.listdir(train_dirPath):\n",
    "  train_age.append(np.array(img.split(\"_\")[0],np.uint64))\n",
    "  train_gender.append(np.array(img.split(\"_\")[1],np.uint64))\n",
    "\n",
    "train_age = np.array(train_age,np.uint64)\n",
    "train_gender = np.array(train_gender,np.uint64)\n",
    "\n",
    "print(\"lenght of UTKFace_trainDataset gender:\",len(train_gender))\n",
    "print(\"train_gender list:\",train_gender)\n",
    "print(\"lenght of UTKFace_trainDataset aga:\", len(train_age))\n",
    "print(\"train_age list:\",train_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_age = []\n",
    "val_gender = [] \n",
    "\n",
    "for img in os.listdir(val_dirPath):\n",
    "  val_age.append(np.array(img.split(\"_\")[0],np.uint64))\n",
    "  val_gender.append(np.array(img.split(\"_\")[1],np.uint64))\n",
    "\n",
    "val_age = np.array(val_age,np.uint64)\n",
    "val_gender = np.array(val_gender,np.uint64)\n",
    "\n",
    "print(len(val_age))\n",
    "print(val_age)\n",
    "print(len(val_gender))\n",
    "print(val_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)  one hot encoding for the train_age  and val_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r lower_agelimit\n",
    "%store -r upper_agelimit\n",
    "\n",
    "print (lower_agelimit)\n",
    "print (upper_agelimit)\n",
    "\n",
    "# Define the age classes\n",
    "# ['1-2', '3-12', '13-19', '20-24', '25-27', '28-30', '31-33', '34-36', '37-40', '41-45', '46-50', '51-55', '56-63', '64-70', '71-116']\n",
    "age_classes = []\n",
    "\n",
    "for lower, upper in zip(lower_agelimit, upper_agelimit):\n",
    "    formatted_range = f\"{lower}-{upper}\"\n",
    "    age_classes.append(formatted_range)\n",
    "\n",
    "print((age_classes))\n",
    "%store age_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_age_to_class(age):\n",
    "    age = int(age)\n",
    "    if age >= lower_agelimit[0] and age <= upper_agelimit[0]:\n",
    "        return age_classes[0]#'1-7'\n",
    "    elif age >= lower_agelimit[1] and age <= upper_agelimit[1]:\n",
    "        return age_classes[1]#'8-12'\n",
    "    elif age >= lower_agelimit[2] and age <= upper_agelimit[2]:\n",
    "        return age_classes[2]#'13-18'\n",
    "    elif age >= lower_agelimit[3] and age <= upper_agelimit[3]:\n",
    "        return age_classes[3]#'19-24'\n",
    "    elif age >= lower_agelimit[4] and age <= upper_agelimit[4]:\n",
    "        return age_classes[4]#'25-30'\n",
    "    elif age >= lower_agelimit[5] and age <= upper_agelimit[5]:\n",
    "        return age_classes[5]#'31-36'\n",
    "    elif age >= lower_agelimit[6] and age <= upper_agelimit[6]:\n",
    "        return age_classes[6]#'37-41'\n",
    "    elif age >= lower_agelimit[7] and age <= upper_agelimit[7]:\n",
    "        return age_classes[7]#'42-47'\n",
    "    elif age >= lower_agelimit[8] and age <= upper_agelimit[8]:\n",
    "        return age_classes[8]#'48-53'\n",
    "    # elif age >= lower_agelimit[9] and age <= upper_agelimit[9]:\n",
    "    #     return age_classes[9]#'54-58'\n",
    "    # elif age >= lower_agelimit[10] and age <= upper_agelimit[10]:\n",
    "    #     return age_classes[10]#'59-64'\n",
    "    # elif age >= lower_agelimit[11] and age <= upper_agelimit[11]:\n",
    "    #     return age_classes[11]#'65-70'\n",
    "    else:\n",
    "        return age_classes[9]#'71-116'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ages to age classes\n",
    "val_age_classes_mapped = [map_age_to_class(age) for age in val_age]\n",
    "train_age_classes_mapped = [map_age_to_class(age) for age in train_age]\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Reshape the mapped age classes into a 2D array\n",
    "val_age_classes_mapped_2d = np.array(val_age_classes_mapped).reshape(-1, 1)\n",
    "train_age_classes_mapped_2d = np.array(train_age_classes_mapped).reshape(-1, 1)\n",
    "\n",
    "# Fit and transform the OneHotEncoder on the reshaped array of train age \n",
    "val_age_encoded = (encoder.fit_transform(val_age_classes_mapped_2d)).astype(int)\n",
    "train_age_encoded = (encoder.fit_transform(train_age_classes_mapped_2d)).astype(int)\n",
    "\n",
    "# Print the result\n",
    "print(len(train_age_encoded))\n",
    "print(len(train_age_encoded[0]))\n",
    "\n",
    "print(\"train_age_encoded:\\n\",(train_age_encoded))\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(len(val_age_encoded))\n",
    "print(len(val_age_encoded[0]))\n",
    "\n",
    "print(\"val_age_encoded:\\n\",(val_age_encoded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #7**: CNN model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Define the CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "#,kernel_regularizer=l2(0.001),\n",
    "input = Input(shape = (100,100,3), name=\"face_image\")\n",
    "\n",
    "conv2d_1 =Conv2D(32, (3,3), activation='relu',name=\"conv2d_1\")(input)\n",
    "maxpool2d_1 = MaxPooling2D(pool_size = (2,2),name=\"maxpool2d_1\") (conv2d_1)\n",
    "BN_01=BatchNormalization(name=\"BN_01\") (maxpool2d_1)\n",
    "\n",
    "conv2d_2 =Conv2D(64, (3,3), activation='relu',name=\"conv2d_2\")(BN_01)\n",
    "maxpool2d_2 = MaxPooling2D(pool_size = (2,2),name=\"maxpool2d_2\") (conv2d_2)\n",
    "BN_02=BatchNormalization(name=\"BN_02\") (maxpool2d_2)\n",
    "\n",
    "###\n",
    "conv2d_3 =Conv2D(128, (3,3), activation='relu',name=\"conv2d_3\")(maxpool2d_2)\n",
    "maxpool2d_3 = MaxPooling2D(pool_size = (2,2),name=\"maxpool2d_3\") (conv2d_3)\n",
    "BN_03=BatchNormalization(name=\"BN_03\") (maxpool2d_3)\n",
    "\n",
    "####\n",
    "conv2d_4 =Conv2D(256, (3,3), activation='relu', name=\"conv2d_4\")(BN_03)\n",
    "maxpool2d_4 = MaxPooling2D(pool_size = (2,2), name=\"maxpool2d_4\") (conv2d_4)\n",
    "BN_04=BatchNormalization(name=\"BN_04\") (maxpool2d_4)\n",
    "\n",
    "\n",
    "#conv2d_4a =Conv2D(256, (3,3), activation='relu', name=\"conv2d_4a\")(maxpool2d_4)\n",
    "#maxpool2d_4a = MaxPooling2D(pool_size = (2,2), name=\"maxpool2d_4a\") (conv2d_4a)\n",
    "\n",
    "flatten = Flatten(name=\"flatten\")(BN_04)\n",
    "\n",
    "FC_dense_1 = Dense(256,activation='relu', name=\"FC_dense_1\")(flatten)\n",
    "FC_dense_2 = Dense(256,activation='relu', name=\"FC_dense_2\")(FC_dense_1)\n",
    "FC_dense_3 = Dense(256,activation='relu', name=\"FC_dense_3\")(FC_dense_2)\n",
    "BN_05=BatchNormalization(name=\"BN_05\") (FC_dense_3)\n",
    "\n",
    "#FC_dense_4 = Dense(256,activation='relu', name=\"FC_dense_4\")(FC_dense_3)\n",
    "#FC_dense_5 = Dense(256,activation='relu', name=\"FC_dense_5\")(FC_dense_4)\n",
    "\n",
    "################################\n",
    "#gender part \n",
    "FC64_dense_gender = Dense(128,activation='relu', name=\"FC64_dense_gender\")(BN_05)\n",
    "drop_1 = Dropout(0.5, name=\"drop_1\")(FC64_dense_gender)\n",
    "#FC32_dense_gender = Dense(32,activation='relu', name=\"FC32_dense_gender\")(FC64_dense_gender)\n",
    "FC16_dense_gender = Dense(64,activation='relu', name=\"FC16_dense_gender\")(drop_1)\n",
    "FC16_dense_gender_01 = Dense(32,activation='relu', name=\"FC16_dense_gender_01\")(FC16_dense_gender)\n",
    "BN_07=BatchNormalization(name=\"BN_07\") (FC16_dense_gender_01)\n",
    "\n",
    "output_gender = Dense(1,activation=\"sigmoid\", name=\"gender_output\")(BN_07)\n",
    "\n",
    "################################\n",
    "#age part \n",
    "FC128_dense_age_01 = Dense(128,activation='relu', name=\"FC128_dense_age_01\")(BN_05)\n",
    "FC128_dense_age_02 = Dense(128,activation='relu', name=\"FC128_dense_age_02\")(FC128_dense_age_01)\n",
    "#drop_gender_1 = Dropout(0.2, name=\"drop_gender_1\")(FC128_dense_age_01)\n",
    "#FC128_dense_age_02 = Dense(128,activation='relu', name=\"FC128_dense_age_02\")(FC128_dense_age_01)\n",
    "FC64_dense_age_03 = Dense(128,activation='relu', name=\"FC64_dense_age_03\")(FC128_dense_age_02)\n",
    "FC64_dense_age_04 = Dense(64,activation='relu', name=\"FC64_dense_age_04\")(FC64_dense_age_03)\n",
    "FC32_dense_age_05 = Dense(32,activation='relu', name=\"FC32_dense_age_05\")(FC64_dense_age_04)\n",
    "BN_06=BatchNormalization(name=\"BN_06\") (FC32_dense_age_05)\n",
    "\n",
    "# FC32_dense_age_06 = Dense(32,activation='relu', name=\"FC32_dense_age_06\")(FC32_dense_age_05)\n",
    "# FC16_dense_age = Dense(16,activation='relu', name=\"FC16_dense_age\")(FC32_dense_age_06)\n",
    "output_age = Dense(10,activation=\"softmax\", name=\"age_output\")(BN_06)\n",
    "\n",
    "output=[output_gender,output_age]\n",
    "DLmodel = Model(inputs=input,outputs=output, name=\"DL_model\")\n",
    "\n",
    "DLmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the train and test directories exist\n",
    "os.makedirs(CNNmodel_dirPath, exist_ok=True)\n",
    "\n",
    "import pydotplus.graphviz as gv\n",
    "\n",
    "# Specify the GraphViz executable path\n",
    "gv.find_graphviz()\n",
    "\n",
    "# Now try to plot the model\n",
    "from keras.utils import plot_model\n",
    "plot_model(DLmodel, to_file=result_filepath+\"/model_architecture.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLmodel.compile(optimizer=\"adam\",loss=[\"binary_crossentropy\",\"categorical_crossentropy\"],metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) saving the model in hd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=result_filepath+\"/\"+str(saveMLmodelfile_name)+\".h5\"\n",
    "checkpointer = ModelCheckpoint(model_path, monitor='loss',verbose=1,save_best_only=True,\n",
    "                               save_weights_only=False, mode='auto',save_freq='epoch')\n",
    "callback_list=[checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RealTimePlot(Callback):\n",
    "    def __init__(self):\n",
    "        super(RealTimePlot, self).__init__()\n",
    "        self.fig, self.ax = plt.subplots(ncols=2, figsize=(15,7), sharex=True, sharey=True)\n",
    "        self.fig.suptitle(\"Lineplots showing training and validation loss of CNN model by epochs\", fontsize=16)\n",
    "        self.train_loss = []\n",
    "        self.train_gender_output_loss = []\n",
    "        self.train_age_output_loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_gender_output_loss = []\n",
    "        self.val_age_output_loss = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.train_gender_output_loss.append(logs.get('gender_output_loss'))\n",
    "        self.train_age_output_loss.append(logs.get('age_output_loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.val_gender_output_loss.append(logs.get('val_gender_output_loss'))\n",
    "        self.val_age_output_loss.append(logs.get('val_age_output_loss'))\n",
    "\n",
    "        self.ax[0].cla()\n",
    "        self.ax[0].plot(self.train_loss, label='Train Loss', color='red', marker='o', markersize=5)\n",
    "        self.ax[0].plot(self.train_gender_output_loss, label='train_gender_output_loss', color=\"mediumpurple\", marker='o', markersize=5)\n",
    "        self.ax[0].plot(self.train_age_output_loss, label='train_age_output_loss', color='royalblue', marker='o', markersize=5)\n",
    "        self.ax[0].set_xlabel('Epochs', fontsize=14)\n",
    "        self.ax[0].set_ylabel(\"binary or categorical  Crossentropy loss\", fontsize=14)\n",
    "        self.ax[0].legend(fontsize=14)\n",
    "        self.ax[0].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "        self.ax[1].cla()\n",
    "        self.ax[1].plot(self.val_loss, label='val Loss', color='red', marker='*', markersize=5)\n",
    "        self.ax[1].plot(self.val_gender_output_loss, label='val_gender_output_loss', color=\"mediumpurple\", marker='*', markersize=5)\n",
    "        self.ax[1].plot(self.val_age_output_loss, label='val_age_output_loss', color='royalblue', marker='*', markersize=5)\n",
    "        self.ax[1].set_xlabel('Epochs', fontsize=14)\n",
    "        self.ax[1].set_ylabel(\"binary or categorical  Crossentropy loss\", fontsize=14)\n",
    "        self.ax[1].legend(fontsize=14)\n",
    "        self.ax[1].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_faceImage = np.array(train_faceImage)\n",
    "train_gender = np.array(train_gender,np.uint64)\n",
    "val_faceImage = np.array(val_faceImage)\n",
    "val_gender = np.array(val_gender,np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_time_plot = RealTimePlot()\n",
    "save = DLmodel.fit(train_faceImage,[train_gender,train_age_encoded],batch_size=512,validation_data=(val_faceImage,[val_gender,val_age_encoded]),epochs=25,callbacks=[callback_list])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loss ##########################\n",
    "train_loss = save.history['loss']\n",
    "print(\"train_loss\",train_loss)\n",
    "train_gender_output_loss = save.history['gender_output_loss']\n",
    "print(\"train_gender_output_loss\",train_gender_output_loss)\n",
    "train_age_output_loss = save.history['age_output_loss']\n",
    "print(\"train_age_output_loss\",train_age_output_loss)\n",
    "# train accuracy ##########################\n",
    "gender_output_accuracy = save.history['gender_output_accuracy']\n",
    "print(\"gender_output_accuracy\",gender_output_accuracy)\n",
    "age_output_accuracy = save.history['age_output_accuracy']\n",
    "print(\"age_output_accuracy\",age_output_accuracy)\n",
    "\n",
    "# validation loss ##########################\n",
    "val_loss = save.history['val_loss']\n",
    "print(\"val_loss\",val_loss)\n",
    "val_gender_output_loss = save.history['val_gender_output_loss']\n",
    "print(\"val_gender_output_loss\",val_gender_output_loss)\n",
    "val_age_output_loss = save.history['val_age_output_loss']\n",
    "print(\"val_age_output_loss\",val_age_output_loss)\n",
    "# validation accuracy ##########################\n",
    "val_gender_output_accuracy = save.history['val_gender_output_accuracy']\n",
    "print(\"val_gender_output_accuracy\",val_gender_output_accuracy)\n",
    "val_age_output_accuracy = save.history['val_age_output_accuracy']\n",
    "print(\"val_age_output_accuracy\",val_age_output_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loss mean ##########################\n",
    "train_loss_mean=sum(train_loss)/len(train_loss)\n",
    "print(\"train_loss_mean:\",train_loss_mean)\n",
    "train_gender_output_loss_mean=sum(train_gender_output_loss)/len(train_gender_output_loss)\n",
    "print(\"train_gender_output_loss_mean:\",train_gender_output_loss_mean)\n",
    "train_age_output_loss_mean=sum(train_age_output_loss)/len(train_age_output_loss)\n",
    "print(\"train_age_output_loss_mean:\",train_age_output_loss_mean)\n",
    "# train accuracy ##########################\n",
    "gender_output_accuracy_mean=sum(gender_output_accuracy)/len(gender_output_accuracy)\n",
    "print(\"\\ngender_output_accuracy_mean:\",gender_output_accuracy_mean)\n",
    "age_output_accuracy_mean=sum(age_output_accuracy)/len(age_output_accuracy)\n",
    "print(\"age_output_accuracy_mean:\",age_output_accuracy_mean)\n",
    "# validation loss ##########################\n",
    "val_loss_mean=sum(val_loss)/len(val_loss)\n",
    "print(\"\\nval_loss_mean:\",val_loss_mean)\n",
    "val_gender_output_loss_mean=sum(val_gender_output_loss)/len(val_gender_output_loss)\n",
    "print(\"val_gender_output_loss_mean:\",val_gender_output_loss_mean)\n",
    "val_age_output_loss_mean=sum(val_age_output_loss)/len(val_age_output_loss)\n",
    "print(\"val_age_output_loss_mean:\",val_age_output_loss_mean)\n",
    "\n",
    "# validation accuracy ##########################\n",
    "val_gender_output_accuracy_mean=sum(val_gender_output_accuracy)/len(val_gender_output_accuracy)\n",
    "print(\"\\nval_gender_output_accuracy_mean:\",val_gender_output_accuracy_mean)\n",
    "val_age_output_accuracy_mean=sum(val_age_output_accuracy)/len(val_age_output_accuracy)\n",
    "print(\"val_age_output_accuracy_mean:\",val_age_output_accuracy_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Plotting a line chart to visualize the loss and accuracy values by epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a line chart to visualize the loss and accuracy values by epochs.\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15,7),sharex=True, sharey=True) \n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='red', marker='o', markersize=5)\n",
    "ax[0].plot(train_gender_output_loss, label='train_gender_output_loss', color=\"mediumpurple\", marker='o', markersize=5)\n",
    "ax[0].plot(train_age_output_loss, label='train_age_output_loss', color='royalblue', marker='o', markersize=5)\n",
    "#ax[0].plot(val_loss, label='val Loss', color = 'orangered', marker='o', markersize=5)\n",
    "ax[0].set_xlabel('Epochs', fontsize=14)\n",
    "ax[0].set_ylabel(\"binary or categorical  Crossentropy loss\", fontsize=14)\n",
    "ax[0].legend(fontsize=14)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "#gnder_output_loss: 0.3613 - age_output_loss: 2.6563 - gnder_output_accuracy: 0.8555 - age_output_accuracy: 0.1491\n",
    "# loss: 3.0175 - \n",
    "# gender_output_loss: 0.3613 - \n",
    "# age_output_loss: 2.6563 - \n",
    "# gnder_output_accuracy: 0.8555 \n",
    "# age_output_accuracy: 0.1491 -\n",
    "# val_loss: 2.6561 \n",
    "# val_gnder_output_loss: 0.3314 \n",
    "# val_age_output_loss: 2.3247 \n",
    "# val_gnder_output_accuracy: 0.8573 \n",
    "# val_age_output_accuracy: 0.2125\n",
    "\n",
    "ax[1].plot(val_loss, label='val Loss', color = 'red', marker='*', markersize=5)\n",
    "ax[1].plot(val_gender_output_loss, label='val_gender_output_loss', color=\"mediumpurple\", marker='*', markersize=5)\n",
    "ax[1].plot(val_age_output_loss, label='val_age_output_loss', color='royalblue', marker='*', markersize=5)\n",
    "\n",
    "ax[1].set_xlabel('Epochs', fontsize=14)\n",
    "ax[1].set_ylabel(\"binary or categorical  Crossentropy loss\", fontsize=14)\n",
    "ax[1].legend(fontsize=14)\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing trainind and validation loss  of CNN model by epochs\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(ncols=2, figsize=(15,7),sharex=True, sharey=True) \n",
    "ax1 = ax1.ravel()\n",
    "ax1[0].plot(gender_output_accuracy, label='gender_output_accuracy', color='royalblue', marker='o', markersize=5)\n",
    "ax1[0].plot(age_output_accuracy, label='age_output_accuracy', color='orangered', marker='o', markersize=5)\n",
    "ax1[0].set_xlabel('Epochs', fontsize=14)\n",
    "ax1[0].set_ylabel('Accuracy', fontsize=14)\n",
    "ax1[0].legend(fontsize=14)\n",
    "ax1[0].tick_params(axis='both', labelsize=12)\n",
    "\n",
    "ax1[1].plot(val_gender_output_accuracy, label='val_gender_output_accuracy', color = 'red', marker='*', markersize=5)\n",
    "ax1[1].plot(val_age_output_accuracy, label='val_age_output_accuracy', color=\"mediumpurple\", marker='*', markersize=5)\n",
    "\n",
    "ax1[1].set_xlabel('Epochs', fontsize=14)\n",
    "ax1[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "ax1[1].legend(fontsize=14)\n",
    "ax1[1].tick_params(axis='both', labelsize=12)\n",
    "fig1.suptitle(x=0.5, y=0.92, t=\"Lineplots showing test and validation accuracy of CNN model by epochs\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #8**: save CNN model and performance in cvs file ith moodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) get the CNN model and performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extracting architecture details\n",
    "architecture = []\n",
    "\n",
    "for layer in DLmodel.layers:\n",
    "    layer_type = layer.__class__.__name__\n",
    "    layer_config = layer.get_config()\n",
    "    architecture.append((layer_type, layer_config))\n",
    "\n",
    "# Assuming you have model history containing metrics\n",
    "history = DLmodel.history.history\n",
    "\n",
    "# Convert architecture to a DataFrame\n",
    "architecture_df = pd.DataFrame(architecture, columns=['Layer Type', 'Layer Config'])\n",
    "# Save architecture to CSV\n",
    "#architecture_df.to_csv('cnn_architecture.csv', index=False)\n",
    "# Convert history to a DataFrame\n",
    "history_df = pd.DataFrame(history)\n",
    "# Save history to CSV\n",
    "#history_df.to_csv('training_log.csv', index_label='Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) save  CNN model and performance metric in the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating summaryfile of model instance with different values\n",
    "summaryfile= './model/'+str(saveMLmodelfile_name)+\"/\"+str(saveMLmodelfile_name)+\".xlsx\"\n",
    "\n",
    "# Generating writer engine\n",
    "writer = pd.ExcelWriter(summaryfile, engine='openpyxl')\n",
    "\n",
    "# Adding dataframes to Excel as new sheets\n",
    "architecture_df.to_excel(writer, sheet_name='cnn_architecture', index=False)\n",
    "history_df.to_excel(writer, sheet_name='training_log', index=True,index_label='Epoch')\n",
    "# Saving changes and closing writer\n",
    "writer.book.save(summaryfile)#\"modelsummary.xlsx\")\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
