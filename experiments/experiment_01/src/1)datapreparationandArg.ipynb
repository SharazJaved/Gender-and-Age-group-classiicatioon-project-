{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation for data for the Gender and age classification model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #1**: Import necessary Libraries and file and folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2_version: 4.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "#########################################################33\n",
    "from openpyxl import Workbook\n",
    "from shutil import copyfile\n",
    "########################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#######################################################\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "###########################################\n",
    "# This is a simple keras or tensorflow.keras library import for CNN \n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Input,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "##################################################\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.callbacks import Callback\n",
    "#######################################################\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# This is a simple keras library import for CNN \n",
    "print(\"cv2_version:\",cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'saveMLmodelfile_name' (str)\n",
      "modelname: exp01_genderAge_model\n",
      "Excel summayfile 'experiments/experiment_01/result/summary_exp01.xlsx' has been created.\n"
     ]
    }
   ],
   "source": [
    "saveMLmodelfile_name=\"exp01_genderAge_model\"\n",
    "%store saveMLmodelfile_name\n",
    "print(\"modelname:\", saveMLmodelfile_name)\n",
    "\n",
    "summaryFile_name=\"summary_exp01\"\n",
    "# Creating summaryfile of model instance with different values\n",
    "summary_filepath= r'experiments/experiment_01/result/'+summaryFile_name+\".xlsx\"\n",
    "print(f\"Excel summayfile '{summary_filepath}' has been created.\")\n",
    "project_path=(os.path.abspath(os.path.join(os.getcwd() ,\"../../..\")))\n",
    "#print(project_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #2**: import UTKface raw dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Get UTKface Raw datset in raw_faceimage list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total UTKFace rawdataset:  23708\n",
      "UTKFace rawdataset image detail \n",
      "Height = 200, Width = 200, channel=3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_datasetPath =project_path+\"\\\\dataset\\\\UTKFace_original\"\n",
    "\n",
    "raw_faceImage=[]\n",
    "for img in os.listdir(raw_datasetPath): \n",
    "    raw_faceImage.append(np.array(cv2.imread(str(raw_datasetPath)+\"/\"+str(img),-1)))   \n",
    "totalraw_faceImage=len(raw_faceImage)\n",
    "print(\"total UTKFace rawdataset: \", (totalraw_faceImage))\n",
    "#Extracting and Displaying the height and width of an raw faces image\n",
    "raw_faceImage_h, raw_faceImage_w,raw_faceImage_c = raw_faceImage[0].shape[:3]\n",
    "# Displaying the height and width and channel of face image \n",
    "print(\"UTKFace rawdataset image detail \\nHeight = {}, Width = {}, channel={}\".format(raw_faceImage_h, raw_faceImage_w,raw_faceImage_c)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) show the image of  UTKface Raw datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(10, 10, figsize=(15, 13)) \n",
    "fig1.suptitle(\"UTKface Raw datset\", fontsize=20)\n",
    "k = 0\n",
    "for i in range(10): \n",
    "     for j in range(10): \n",
    "         ax1[i][j].imshow(cv2.cvtColor(raw_faceImage[k], cv2.COLOR_BGR2RGB)) \n",
    "         # ax[i][j].set_title('Label: {}'.format(pixels[k]))\n",
    "         k += 1         \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig1.savefig(figure_dirPath+\"UTKFace_rawdataset.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #3**:  Exploratory Data Analysis (EDA) on raw UTKface_rawdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) extraction of age and gender Label or annotation on raw UTKface dataset  \n",
    "\n",
    "**UTK Face Dataset** images have labels embedded in their name, as per the following nomenclature:\n",
    "#####                                         [age]\\_[gender]\\_[race]\\_[time].jpg \n",
    "where\n",
    "\n",
    "\n",
    "* ***[age]*** is an integer from 0 to 116, indicating the age\n",
    "* ***[gender]*** is either 0 (male) or 1 (female)\n",
    "* ***[race]*** is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).\n",
    "* ***[date&time]*** is in the format of yyyymmddHHMMSSFFF, showing the date and time an image was collected to UTKFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_faceFile=[]\n",
    "#we only requird on only two imformation age and gender \n",
    "raw_age = []\n",
    "raw_gender = [] \n",
    "for img in os.listdir(raw_datasetPath):\n",
    "  #if int(img.split(\"_\")[0])>=3 and int(img.split(\"_\")[0])<=65:\n",
    "    raw_faceFile.append(img)\n",
    "    raw_age.append(np.array(img.split(\"_\")[0],np.uint64))\n",
    "    raw_gender.append(np.array(img.split(\"_\")[1],np.uint64))\n",
    "\n",
    "raw_age = np.array(raw_age,np.uint64)\n",
    "raw_gender = np.array(raw_gender,np.uint64)\n",
    "\n",
    "print(\"total # raw_faceFile:\",len(raw_faceFile))\n",
    "print(\"list of raw_faceFile:\", raw_faceFile)\n",
    "print(\"total # raw_gender:\",len(raw_gender))\n",
    "print(\"list of raw_gender:\",raw_gender)\n",
    "print(\"total # raw_age:\",len(raw_age))\n",
    "print(\"list of raw_age:\",raw_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Check duplication in  raw dataset file name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = len(raw_faceFile) != len(set(raw_faceFile))\n",
    "print(\"Duplicates found in the\", raw_datasetPath ,\":\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Check Distribution of gender in raw dataset for any Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count male and female reviews\n",
    "unique, counts = np.unique(raw_gender, return_counts=True)\n",
    "gender_distribution = dict(zip(unique, counts))\n",
    "print(\"raw_gender_distribution:\",gender_distribution)\n",
    "# Visualize the distribution on the bar bar graph\n",
    "plt.bar(gender_distribution.keys(), gender_distribution.values(), color=['blue', 'red'])\n",
    "# Add text annotations to each bar\n",
    "for i, value in enumerate(gender_distribution.values()):\n",
    "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "plt.title(\"gender Distribution of UTKFace_rawdataset\")\n",
    "plt.xlabel('gender class')\n",
    "plt.ylabel('Number of UTKFace_rawdataset image file')\n",
    "plt.xticks([0, 1], ['male', 'female'])\n",
    "plt.tick_params(labelleft=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figure_dirPath+\"/gender_Distribution_of_UTKFace_rawdataset.png\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Check duplication in  raw dataset file name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = len(raw_faceFile) != len(set(raw_faceFile))\n",
    "print(\"Duplicates found in the\", raw_datasetPath ,\":\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Check Distribution of age for any Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 7))\n",
    "# Count male and female reviews\n",
    "unique, counts = np.unique(raw_age, return_counts=True)\n",
    "age_distribution = dict(zip(unique, counts))\n",
    "# Print information about the data\n",
    "print(\"List of age:\", unique)\n",
    "\n",
    "print(\"\\nNumber of unique ages:\", len(age_distribution))\n",
    "print(\"\\nage Distribution of UTKFace_rawdataset:\", age_distribution)\n",
    "print(\"\\nMaximum age count:\", max(age_distribution.values()))\n",
    "max_age = max(age_distribution, key=lambda k: age_distribution[k])\n",
    "print(\"Age with maximum count:\", max_age,\" year\")\n",
    "# Visualize the distribution\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd','#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "plt.bar(age_distribution.keys(), age_distribution.values(), color=colors)#['blue', 'red'])\n",
    "plt.title(\"age Distribution of UTKFace_rawdataset\")\n",
    "plt.xlabel('age(1-116 ')\n",
    "plt.ylabel('Number of UTKFace_rawdataset image file')\n",
    "plt.tick_params(labelbottom=True)\n",
    "#plt.xticks([0, 1], ['male', 'female'])\n",
    "# Limit x and y labels\n",
    "plt.xlim(-1,117)  # Add buffer to avoid cutting off bars\n",
    "plt.savefig(figure_dirPath+\"age_Distribution_of_UTKFace_rawdataset.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Check descriptive statistics of age of UTKFace_rawdataser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a pandas Series\n",
    "series = pd.Series(raw_age)\n",
    "# Get descriptive statistics\n",
    "descri_stat = (pd.Series(raw_age)).describe()\n",
    "print( \"descriptive statistics in the age\", descri_stat)\n",
    "print(\"Skewness:\", skew(raw_age)) # Calculate skewness\n",
    "print(\"Kurtosis:\", kurtosis(raw_age))# Calculate kurtosis\n",
    "# Create a box plot\n",
    "plt.boxplot(raw_age,vert=0)\n",
    "# Add labels and title\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Box Plot')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #4**:  extract the extractraw_datasetPath from raw_datasetPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_faceFile=[]\n",
    "#we only requird on only two imformation age and gender \n",
    "for img in os.listdir(raw_datasetPath):\n",
    "    if int(img.split(\"_\")[0])>=3 and int(img.split(\"_\")[0])<=65:\n",
    "        raw_faceFile.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractraw_datasetPath = r\"dataset/UTKFace_extractRawDataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for your dataset\n",
    "extractraw_datasetPath = r\"dataset/UTKFace_extractRawDataset\"\n",
    "\n",
    "# Ensure the train and test directories exist\n",
    "os.makedirs(extractraw_datasetPath, exist_ok=True)\n",
    "\n",
    "# List all image files in the original dataset directory\n",
    "#image_files = [f for f in os.listdir(raw_datasetPath) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "#print(type(image_files[0]))\n",
    "\n",
    "# Copy extractraw images to the train directory\n",
    "for file in raw_faceFile:\n",
    "    src_path = os.path.join(raw_datasetPath, file)\n",
    "    dest_path = os.path.join(extractraw_datasetPath, file)\n",
    "    print(src_path, dest_path)\n",
    "    copyfile(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #5**:  Exploratory Data Analysis  (EDA) on raw UTKface extracteddataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) extraction of age and gender Label or annotation on extracted UTKface dataset  \n",
    "\n",
    "**UTK Face Dataset** images have labels embedded in their name, as per the following nomenclature:\n",
    "#####                                         [age]\\_[gender]\\_[race]\\_[time].jpg \n",
    "where\n",
    "\n",
    "\n",
    "* ***[age]*** is an integer from 0 to 116, indicating the age\n",
    "* ***[gender]*** is either 0 (male) or 1 (female)\n",
    "* ***[race]*** is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).\n",
    "* ***[date&time]*** is in the format of yyyymmddHHMMSSFFF, showing the date and time an image was collected to UTKFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractraw_faceFile=[]\n",
    "extractraw_faceImage=[]\n",
    "#we only requird on only two imformation age and gender \n",
    "extractraw_age = []\n",
    "extractraw_gender = [] \n",
    "for img in os.listdir(extractraw_datasetPath):\n",
    "  if int(img.split(\"_\")[0])>=3 and int(img.split(\"_\")[0])<=65:\n",
    "    extractraw_faceImage.append(np.array(cv2.imread(str(extractraw_datasetPath)+\"/\"+str(img),-1)))   \n",
    "    extractraw_faceFile.append(img)\n",
    "    extractraw_age.append(np.array(img.split(\"_\")[0],np.uint64))\n",
    "    extractraw_gender.append(np.array(img.split(\"_\")[1],np.uint64))\n",
    "\n",
    "extractraw_age = np.array(extractraw_age,np.uint64)\n",
    "extractraw_gender = np.array(extractraw_gender,np.uint64)\n",
    "\n",
    "print(\"total # extractraw_faceFile:\",len(extractraw_faceFile))\n",
    "print(\"list of extractraw_faceFile:\", extractraw_faceFile)\n",
    "print(\"total # extractraw_gender:\",len(extractraw_gender))\n",
    "print(\"list of extractraw_gender:\",extractraw_gender)\n",
    "print(\"total # extractraw_age:\",len(extractraw_age))\n",
    "print(\"list of extractraw_age:\",extractraw_age)\n",
    "print(\"total # extractraw_faceImage:\",len(extractraw_faceImage))\n",
    "print(\"list of extractraw_faceImage:\", extractraw_faceImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Check duplication in  raw dataset file name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = len(extractraw_faceFile) != len(set(extractraw_faceFile))\n",
    "print(\"Duplicates found in the\", extractraw_datasetPath ,\":\", duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Check Distribution of gender in raw dataset for any Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count male and female reviews\n",
    "unique, counts = np.unique(extractraw_gender, return_counts=True)\n",
    "gender_distribution = dict(zip(unique, counts))\n",
    "print(\"raw_gender_distribution:\",gender_distribution)\n",
    "# Visualize the distribution on the bar bar graph\n",
    "plt.bar(gender_distribution.keys(), gender_distribution.values(), color=['blue', 'red'])\n",
    "# Add text annotations to each bar\n",
    "for i, value in enumerate(gender_distribution.values()):\n",
    "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
    "\n",
    "plt.title(\"gender Distribution of UTKFace_extractrawdataset\")\n",
    "plt.xlabel('gender class')\n",
    "plt.ylabel('Number of UTKFace_extractrawdataset image file')\n",
    "plt.xticks([0, 1], ['male', 'female'])\n",
    "plt.tick_params(labelleft=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figure_dirPath+\"/gender_Distribution_of_UTKFace_extractrawdataset.png\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Check Distribution of age for any Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 7))\n",
    "# Count male and female reviews\n",
    "unique, counts = np.unique(extractraw_age, return_counts=True)\n",
    "age_distribution = dict(zip(unique, counts))\n",
    "# Print information about the data\n",
    "print(\"List of age:\", unique)\n",
    "\n",
    "print(\"\\nNumber of unique ages:\", len(age_distribution))\n",
    "print(\"\\nage Distribution of UTKFace_extractrawdataset:\", age_distribution)\n",
    "print(\"\\nMaximum age count:\", max(age_distribution.values()))\n",
    "max_age = max(age_distribution, key=lambda k: age_distribution[k])\n",
    "print(\"Age with maximum count:\", max_age,\" year\")\n",
    "# Visualize the distribution\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd','#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "plt.bar(age_distribution.keys(), age_distribution.values(), color=colors)#['blue', 'red'])\n",
    "plt.title(\"age Distribution of UTKFace_extractrawdataset\")\n",
    "plt.xlabel('age(1-116 ')\n",
    "plt.ylabel('Number of UTKFace_extractrawdataset image file')\n",
    "plt.tick_params(labelbottom=True)\n",
    "#plt.xticks([0, 1], ['male', 'female'])\n",
    "# Limit x and y labels\n",
    "plt.xlim(-1,117)  # Add buffer to avoid cutting off bars\n",
    "plt.savefig(figure_dirPath+\"age_Distribution_of_UTKFace_rawdataset.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Histrogram for the age distribution by only given bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer a histotgram for the age classificaiton but nned t0 calculated the number and size of  bin for  calculated the number and size of  bin  \n",
    "#decide on the number of bins of a Histogram?  \n",
    "plt.hist(extractraw_age, bins=12, alpha=0.7,edgecolor='black')\n",
    "plt.title('Histogram of age extractdDataset')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) compute number and size of bin for Histrogram of age distribution using  data binning technique (square_root_bins, sturges_bins ,scotts_bins, freedman_diaconis_bins and doanes_bins) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def square_root_bins(data):\n",
    "    return int(np.sqrt(len(data)))\n",
    "\n",
    "def sturges_bins(data):\n",
    "    return int(1 + np.log2(len(data)))\n",
    "\n",
    "def scotts_bins(data):\n",
    "    sigma = np.std(data)\n",
    "    return int((np.max(data) - np.min(data)) / (3.5 * sigma / np.cbrt(len(data))))\n",
    "\n",
    "def freedman_diaconis_bins(data):\n",
    "    q1, q3 = np.percentile(data, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    return int((np.max(data) - np.min(data)) / (2 * iqr / np.cbrt(len(data))))\n",
    "\n",
    "def doanes_bins(data):\n",
    "    n = len(data)\n",
    "    g1 = skew(data)\n",
    "    sigma_g1 = np.sqrt((6 * (n - 2)) / ((n + 1) * (n + 3)))\n",
    "    return int(1 + np.log2(n) + np.log2(1 + np.abs(g1) / sigma_g1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of bins using each method\n",
    "num_bins_square_root = square_root_bins(extractraw_age)\n",
    "num_bins_sturges = sturges_bins(extractraw_age)\n",
    "num_bins_scotts = scotts_bins(extractraw_age)\n",
    "num_bins_freedman_diaconis = freedman_diaconis_bins(extractraw_age)\n",
    "num_bins_doanes = doanes_bins(extractraw_age)\n",
    "\n",
    "# Create histograms with different bin selections\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(extractraw_age, bins=num_bins_square_root, edgecolor='black')\n",
    "#print(SRR_bin_edges)\n",
    "plt.title('Square Root Rule')\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.hist(extractraw_age, bins=num_bins_sturges, edgecolor='black')\n",
    "#print(bin_edges)\n",
    "plt.title('Sturges Formula')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.hist(extractraw_age, bins=num_bins_scotts, edgecolor='black')\n",
    "#print(bin_edges)\n",
    "plt.title(\"Scott's Rule\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(extractraw_age, bins=num_bins_freedman_diaconis, edgecolor='black')\n",
    "#print(bin_edges)\n",
    "plt.title('Freedman-Diaconis Rule')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "Doane_Numofbine_edge= plt.hist(extractraw_age, bins=num_bins_doanes, edgecolor='black')\n",
    "plt.title(\"Doane's Formula\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print (\"Doane_Numofbine_edge_value: \",Doane_Numofbine_edge[0])\n",
    "print (\"\\nDoane_Numofbine_edge: \",(Doane_Numofbine_edge[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"num_bins_doanes: \",num_bins_doanes)\n",
    "print (\"\\nnum_bins_doanes_value: \", (Doane_Numofbine_edge[1]))\n",
    "rounded_doanes_binEdge = [round(num) for num in (Doane_Numofbine_edge[1])]\n",
    "print(\"\\nrounded_doanes_binEdge: \",rounded_doanes_binEdge)\n",
    "\n",
    "# Exclude specific intervals\n",
    "#excluded_intervals = [76, 82, 87, 93, 99, 104, 110]\n",
    "# Filter out excluded intervals\n",
    "#filtered_classbin = [interval for interval in rounded_doanes_binEdge if interval not in excluded_intervals]\n",
    "# Define intervals\n",
    "#print(\"\\nfiltered_classbin: \",filtered_classbin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rounded_doanes_binEdge: \",rounded_doanes_binEdge)\n",
    "first_index = 0 # First index\n",
    "last_index = len(rounded_doanes_binEdge) - 1 # Last index\n",
    "\n",
    "first=rounded_doanes_binEdge[first_index]\n",
    "last=rounded_doanes_binEdge[last_index]\n",
    "remained_list = rounded_doanes_binEdge[1:-1]\n",
    "remained_list_plus_one = [x + 1 for x in remained_list]\n",
    "modified_rounded_doanes_binEdge= [first]+remained_list_plus_one+[last]\n",
    "#print(first,last,remained_list_plus_one)\n",
    "print(\"\\nmodified_rounded_doanes_binEdge: \",modified_rounded_doanes_binEdge)\n",
    "%store modified_rounded_doanes_binEdge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer a histotgram for the age classificaiton but nned t0 calculated the number and size of  bin for  calculated the number and size of  bin  \n",
    "#decide on the number of bins of a Histogram?\n",
    "#[1 2 3 4] bin are [1 2) [2 3) [3 4] \n",
    "hist=plt.hist(extractraw_age, bins=modified_rounded_doanes_binEdge,  alpha=0.7, edgecolor='black')\n",
    "print(\"no of file image: \",hist[0])\n",
    "print(\"interval of bin: \",hist[1])\n",
    "\n",
    "plt.title('age Distribution histrogram of UTKFace_extractdataset')\n",
    "plt.xlabel('age interval Value')\n",
    "plt.ylabel('Frequency of UTKFace_extractdataset image')\n",
    "plt.grid(True)\n",
    "plt.savefig(figure_dirPath+\"age_Distribution_histrogram_of_UTKFace_extractrawdataset.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Check two-way Distribution of age and gender for any two-Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGender_MF(face_gender):   \n",
    "    unique, counts = np.unique(face_gender, return_counts=True)\n",
    "    #print(\"list of age=\", unique)      \n",
    "    processedgender_distribution = dict(zip(unique, counts))\n",
    "    #print(\"raw_gender:\",processedgender_distribution)\n",
    "    return processedgender_distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"\\nrounded_doanes_binEdge: \",rounded_doanes_binEdge)\n",
    "\n",
    "\"\"\" ## define the class for aage interval\n",
    "age_classname= ['child_1_7',\n",
    "            'kid_8_12',\n",
    "            'teenager_13_18',\n",
    "            'EarlyAdulthood_19_24',\n",
    "            'EarlyAdulthood_25_30',\n",
    "            'YoungAdulthood_31_36',\n",
    "            'YoungAdulthood_37_41',\n",
    "            'middleAdulthood_42_47',\n",
    "            'middleAdulthood_48_53',\n",
    "            'middleAdulthood_54_58',\n",
    "            'middleAdulthood_59_64',\n",
    "            'middleAdulthood_65_70',\n",
    "            #'middleAdulthood_71_76',\n",
    "            \"senior_71_116\"]\n",
    "            # \"senior_77_82\",\n",
    "            # \"senior_83_87\",\n",
    "            # \"senior_88_93\",\n",
    "            # \"senior_94_99\",\n",
    "            # \"senior_100_104\",\n",
    "            # \"senior_105_110\",\n",
    "            # \"senior_111_116\"] \"\"\"\n",
    "#%store age_classname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classname= ['child_3_6',\n",
    "            'kid_7_12',\n",
    "            'teenager_13_19',\n",
    "            'EarlyAdulthood_20_26',\n",
    "            'EarlyAdulthood_27_32',\n",
    "            'YoungAdulthood_33_40',\n",
    "            'middleAdulthood_41_45',\n",
    "            'middleAdulthood_46_50',\n",
    "            'middleAdulthood_51_56',\n",
    "            'senior_57_65']\n",
    "%store age_classname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname_dict_ageGender={}\n",
    "lower_agelimit=[]\n",
    "upper_agelimit=[]\n",
    "\n",
    "for agevariable in age_classname:\n",
    "    lower_agelimit.append(int(agevariable.split(\"_\")[1]))\n",
    "    upper_agelimit.append(int(agevariable.split(\"_\")[2]))\n",
    "\n",
    "print (\"lower_agelimit: \",lower_agelimit)\n",
    "print (\"upper_agelimit: \",upper_agelimit)\n",
    "\n",
    "%store lower_agelimit\n",
    "%store upper_agelimit\n",
    "\n",
    "age_bagg=[]\n",
    "gender_bagg=[]\n",
    "\n",
    "for classe,lowerage,upperage in zip(age_classname,lower_agelimit,upper_agelimit):\n",
    "    #print(classe,lowerage,upperage)\n",
    "    for age,gender in zip(extractraw_age,extractraw_gender):\n",
    "        if age>=(lowerage) and age<=upperage:\n",
    "            age_bagg.append(age)\n",
    "            gender_bagg.append(gender)\n",
    "            classname_dict_ageGender[(classe)]=[len(age_bagg), (countGender_MF(gender_bagg))]  \n",
    "    age_bagg.clear()\n",
    "    gender_bagg.clear()\n",
    "    \n",
    "print(\"\\nclassname_dict: \",classname_dict_ageGender)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "row = []\n",
    "# Iterate over all age groups and their counts\n",
    "for age_group, count_data in classname_dict_ageGender.items():\n",
    "    total_count = count_data[0]\n",
    "    male_count = count_data[1][0]\n",
    "    female_count = count_data[1][1]\n",
    "    # Append data to list\n",
    "    row.append({'ageGroup_L_H': age_group,'total_face': total_count, 'Male_Count': male_count, 'Female_Count': female_count})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "twoWay_table = pd.DataFrame(row)\n",
    "# Display DataFrame\n",
    "print(\"two-way gender-ageGroup Distribution:\\n \",twoWay_table)\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Set the figure size to width=10 and height=6\n",
    "twoWay_table.plot.bar(x='ageGroup_L_H', ax=ax, rot=75, color=['green', 'blue', 'red'])\n",
    "ax.set_xlabel(\"Age Group\")  # Set the label for the x-axis\n",
    "ax.set_ylabel(\"# of face image\")  # Set the label for the x-axis\n",
    "\n",
    "plt.title('gender -- ageGroup Distribution  of UTKFace_extractrawdataset')\n",
    "\n",
    "print(\"\\n\")\n",
    "summary_dict1={ \"total_face\":twoWay_table['total_face'].sum(), \"total_MaleCount\": twoWay_table['Male_Count'].sum(), \"total_FemaleCount\":twoWay_table['Female_Count'].sum()}\n",
    "#print(summary_dict)\n",
    "# Convert summary_dict to DataFrame\n",
    "total_summary_table = pd.DataFrame([summary_dict1])\n",
    "print(total_summary_table)\n",
    "fig.savefig(figure_dirPath+\"gender-ageGroup_Distribution_of_UTKFace_extractrawdataset.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Split processed_UTKdataset file and copy into train, test and validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths for your dataset\n",
    "train_dirPath = r\"dataset/UTKFace_trainDataset\"\n",
    "test_dirPath = r\"dataset/UTKFace_testDataset\"\n",
    "val_dirPath= r\"dataset/UTKFace_valDataset\"\n",
    "\n",
    "\n",
    "# Ensure the train and test directories exist\n",
    "os.makedirs(train_dirPath, exist_ok=True)\n",
    "os.makedirs(test_dirPath, exist_ok=True)\n",
    "os.makedirs(val_dirPath, exist_ok=True)\n",
    "\n",
    "\n",
    "# List all image files in the original dataset directory\n",
    "image_files = [f for f in os.listdir(extractraw_datasetPath) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "#print(image_files)\n",
    "\n",
    "\n",
    "# Split the data into train and test sets \n",
    "# Split data into train and test sets (80% train, 20% test)\n",
    "train_files, test_files = train_test_split(image_files, test_size=0.4, random_state=100)\n",
    "# Split test set into test and validation sets (50% test, 50% validation)\n",
    "test_files, val_files = train_test_split(test_files, test_size=0.5, random_state=100)\n",
    "\n",
    "\n",
    "# Output the sizes of each set\n",
    "print(\"totalprocessed_faceImage: \", len(extractraw_faceImage))\n",
    "print(\"Train set size:\", len(train_files))\n",
    "print(\"Validation set size:\", len(val_files))\n",
    "print(\"Test set size:\", len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy training images to the train directory\n",
    "for file in train_files:\n",
    "    src_path = os.path.join(extractraw_datasetPath, file)\n",
    "    dest_path = os.path.join(train_dirPath, file)\n",
    "    copyfile(src_path, dest_path)\n",
    "\n",
    "# Copy test images to the test directory\n",
    "for file in test_files:\n",
    "    src_path = os.path.join(extractraw_datasetPath, file)\n",
    "    dest_path = os.path.join(test_dirPath, file)\n",
    "    copyfile(src_path, dest_path)\n",
    "    \n",
    "# # Copy test images to the validation directory\n",
    "for file in val_files:\n",
    "    src_path = os.path.join(extractraw_datasetPath, file)\n",
    "    dest_path = os.path.join(val_dirPath, file)\n",
    "    copyfile(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Check two-way Distribution of age and gender for any two-Class Imbalance in utkface_traindataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_age = []\n",
    "train_gender = [] \n",
    "\n",
    "for img in os.listdir(train_dirPath):\n",
    "  train_age.append(np.array(img.split(\"_\")[0],np.uint64))\n",
    "  train_gender.append(np.array(img.split(\"_\")[1],np.uint64))\n",
    "\n",
    "train_age = np.array(train_age,np.uint64)\n",
    "train_gender = np.array(train_gender,np.uint64)\n",
    "\n",
    "print(\"lenght of UTKFace_trainDataset gender:\",len(train_gender))\n",
    "print(\"train_gender list:\",train_gender)\n",
    "print(\"lenght of UTKFace_trainDataset aga:\", len(train_age))\n",
    "print(\"train_age list:\",train_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname_dict_ageGender={}\n",
    "lower_agelimit=[]\n",
    "upper_agelimit=[]\n",
    "\n",
    "for agevariable in age_classname:\n",
    "    lower_agelimit.append(int(agevariable.split(\"_\")[1]))\n",
    "    upper_agelimit.append(int(agevariable.split(\"_\")[2]))\n",
    "\n",
    "print (\"lower_agelimit: \",lower_agelimit)\n",
    "print (\"upper_agelimit: \",upper_agelimit)\n",
    "\n",
    "%store lower_agelimit\n",
    "%store upper_agelimit\n",
    "\n",
    "age_bagg=[]\n",
    "gender_bagg=[]\n",
    "\n",
    "for classe,lowerage,upperage in zip(age_classname,lower_agelimit,upper_agelimit):\n",
    "    #print(classe,lowerage,upperage)\n",
    "    for age,gender in zip(train_age,train_gender):\n",
    "        if age>=(lowerage) and age<=upperage:\n",
    "            age_bagg.append(age)\n",
    "            gender_bagg.append(gender)\n",
    "            classname_dict_ageGender[(classe)]=[len(age_bagg), (countGender_MF(gender_bagg))]  \n",
    "    age_bagg.clear()\n",
    "    gender_bagg.clear()\n",
    "    \n",
    "print(\"\\nclassname_dict: \",classname_dict_ageGender)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "row = []\n",
    "# Iterate over all age groups and their counts\n",
    "for age_group, count_data in classname_dict_ageGender.items():\n",
    "    total_count = count_data[0]\n",
    "    male_count = count_data[1][0]\n",
    "    female_count = count_data[1][1]\n",
    "    # Append data to list\n",
    "    row.append({'ageGroup_L_H': age_group,'total_face': total_count, 'Male_Count': male_count, 'Female_Count': female_count})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "twoWay_table = pd.DataFrame(row)\n",
    "# Display DataFrame\n",
    "print(\"two-way gender-ageGroup Distribution in traindataset:\\n \",twoWay_table)\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # Set the figure size to width=10 and height=6\n",
    "twoWay_table.plot.bar(x='ageGroup_L_H', ax=ax, rot=75, color=['green', 'blue', 'red'])\n",
    "ax.set_xlabel(\"Age Group\")  # Set the label for the x-axis\n",
    "ax.set_ylabel(\"# of face image\")  # Set the label for the x-axis\n",
    "\n",
    "plt.title('gender -- ageGroup Distribution  of UTKFace_traindataset')\n",
    "\n",
    "print(\"\\n\")\n",
    "summary_dict1={ \"total_face\":twoWay_table['total_face'].sum(), \"total_MaleCount\": twoWay_table['Male_Count'].sum(), \"total_FemaleCount\":twoWay_table['Female_Count'].sum()}\n",
    "#print(summary_dict)\n",
    "# Convert summary_dict to DataFrame\n",
    "total_summary_table = pd.DataFrame([summary_dict1])\n",
    "print(total_summary_table)\n",
    "fig.savefig(figure_dirPath+\"gender-ageGroup_Distribution_of_UTKFace_extractrawdataset.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #5**: image argumentation on UTKFace_extractdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) create a folder for store argumented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argumentraw_datasetPath = r'dataset//UTKFace_argTrainDataset'\n",
    "##############\n",
    "# Two lists of strings\n",
    "gender_classname = ['male', 'female']\n",
    "# Initialize an empty list to store the combined strings\n",
    "age_genderClassName = []\n",
    "# Iterate over each element in age_classname\n",
    "for age_class in age_classname:\n",
    "    # Iterate over each element in gender_classname\n",
    "    for gender_class in gender_classname:\n",
    "        # Concatenate the elements and append to the combined list\n",
    "        age_genderClassName.append(age_class +\"_\"+gender_class)\n",
    "\n",
    "print(\"age_genderClassName: \", age_genderClassName)\n",
    "print(\"\\n\")\n",
    "################################\n",
    "for classname in age_genderClassName:\n",
    "    folder_path = os.path.join(argumentraw_datasetPath, classname)\n",
    "    #os.makedirs(folder_path)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) create a two way frequency table fro the need of image argumentation in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from the list of dictionaries\n",
    "twoWay_table = pd.DataFrame(row)\n",
    "# Display DataFrame\n",
    "print(\"two-way gender-ageGroup Distribution:\\n \",twoWay_table)\n",
    "# To find the maximum value across all columns\n",
    "max_value_across_all_columns = max(twoWay_table[\"Male_Count\"].values.max() ,twoWay_table[\"Female_Count\"].values.max())\n",
    "print(\"\\nmax_value_across_all_columns\",max_value_across_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data\n",
    "arg_imageNeed = []\n",
    "# Iterate over all age groups and their counts\n",
    "for age_group, count_data in classname_dict_ageGender.items():\n",
    "    male_count_argneed = max_value_across_all_columns-count_data[1][0]\n",
    "    female_count_argneed = max_value_across_all_columns-count_data[1][1]\n",
    "    total_count_argneed = male_count_argneed+female_count_argneed\n",
    "    # Append data to list\n",
    "    arg_imageNeed.append({'ageGroup_L_H': age_group,'totalFaceArgneed': total_count_argneed, 'Maleargneed': (male_count_argneed), 'Femaleargneed':(female_count_argneed)})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "arg_imageNeed_twoWayTable = pd.DataFrame(arg_imageNeed)\n",
    "# Display DataFrame\n",
    "print(\"two-way gender-ageGroup Distribution for arg_imageNeed:\\n \",arg_imageNeed_twoWayTable)\n",
    "totalArgNeed_summary_dict1=[]\n",
    "totalArgNeed_summary_dict1.append({\"total_face_argneed\":(arg_imageNeed_twoWayTable['totalFaceArgneed'].sum()), \"total_MaleCount_argneed\": (arg_imageNeed_twoWayTable['Maleargneed'].sum()), \"total_FemaleCount_argneed\":(arg_imageNeed_twoWayTable['Femaleargneed'].sum())})\n",
    "totalArgNeed_summary_Table = pd.DataFrame(totalArgNeed_summary_dict1)\n",
    "# Display DataFrame\n",
    "print(\"\\ntotalArgNeed_summary_Table:\\n \",totalArgNeed_summary_Table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) generated image argumentation in the each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=100,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 6 1\n",
    "#3 6 2\n",
    "print(lower_agelimit)\n",
    "print(upper_agelimit)\n",
    "\n",
    "print(arg_imageNeed[0][\"Femaleargneed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkkkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable\n",
    "current_iter = 0\n",
    "change_LHrange=0\n",
    "\n",
    "# Loop indefinitely\n",
    "while change_LHrange<=9:\n",
    "    while True:\n",
    "        #print(\"\\ncurrent_iter:\", current_iter)# Increment the value\n",
    "        maleListArg=[]\n",
    "        femaleListArg=[]\n",
    "        for img in os.listdir(extractraw_datasetPath): #male L-H year\n",
    "            if int(img.split(\"_\")[0])>=lower_agelimit[change_LHrange] and int(img.split(\"_\")[0])<=upper_agelimit[change_LHrange] and int(img.split(\"_\")[1])==0:\n",
    "                maleListArg.append(img)\n",
    "        print(\"lenght_maleListArg_\"+str(lower_agelimit[change_LHrange])+\"_\"+str(upper_agelimit[change_LHrange])+\"lenght: \",len(maleListArg))\n",
    "        #print((maleListArg))\n",
    "        # Pick a random number from the list\n",
    "        random_malefile= random.choice(maleListArg)\n",
    "        print(\"random maleListArg_:\",random_malefile)\n",
    "        argumentraw_male_datasetPath = r'dataset//UTKFace_argTrainDataset/'+age_classname[change_LHrange]+\"_male\"\n",
    "        #print(\"argumentraw_male_datasetPath:\",argumentraw_male_datasetPath)\n",
    "        argumentraw_male_totalFiles = len(os.listdir(argumentraw_male_datasetPath))\n",
    "        print(\"argumentraw_male_totalFiles:\",argumentraw_male_totalFiles,\"total:(\"+str(arg_imageNeed[change_LHrange][\"Maleargneed\"])+\") \"+argumentraw_male_datasetPath)\n",
    "        # Load and preprocess a sample image\n",
    "        img_path = os.path.join(extractraw_datasetPath, random_malefile)#\"picture/3_0_0_20161219154705684.jpg.jpg\"\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #i = 0\n",
    "        #Pick a random number from the list\n",
    "        # Generate augmented images and save them\n",
    "        current_iter += 1  \n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=argumentraw_male_datasetPath, save_prefix=random_malefile, save_format='jpeg'):\n",
    "                #i += 1\n",
    "                #if i % 1 == 0:  # Generate 1 augmented images\n",
    "            break # break the generation loop\n",
    "        #(50-1):\n",
    "        if argumentraw_male_totalFiles>=((arg_imageNeed[change_LHrange][\"Maleargneed\"])-1):\n",
    "            print(\"Value reached \"+str((arg_imageNeed[change_LHrange][\"Maleargneed\"])) +\" Exiting loop.\")\n",
    "            break  # Exit the loop\n",
    "\n",
    "    change_LHrange+=1\n",
    "    print(\"Loop ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable\n",
    "current_iter = 0\n",
    "change_LHrange=0\n",
    "\n",
    "# Loop indefinitely\n",
    "while change_LHrange<=9:\n",
    "    while True:\n",
    "        #print(\"\\ncurrent_iter:\", current_iter)# Increment the value\n",
    "        femaleListArg=[]\n",
    "        for img in os.listdir(extractraw_datasetPath): #female L-H year\n",
    "            if int(img.split(\"_\")[0])>=lower_agelimit[change_LHrange] and int(img.split(\"_\")[0])<=upper_agelimit[change_LHrange] and int(img.split(\"_\")[1])==1:\n",
    "                femaleListArg.append(img)\n",
    "        \n",
    "        #print(\"lenght_femaleListArg_\"+str(lower_agelimit[change_LHrange])+\"_\"+str(upper_agelimit[change_LHrange])+\"lenght: \",len(femaleListArg))\n",
    "        print(len(femaleListArg))\n",
    "        # Pick a random number from the list\n",
    "        random_femalefile= random.choice(femaleListArg)\n",
    "        print(\"random feListArg :\",random_femalefile)\n",
    "        argumentraw_female_datasetPath = r'dataset//UTKFace_argTrainDataset/'+age_classname[change_LHrange]+\"_female\"\n",
    "        #print(\"argumentraw_male_datasetPath:\",argumentraw_male_datasetPath)\n",
    "        argumentraw_female_totalFiles = len(os.listdir(argumentraw_female_datasetPath))\n",
    "        print(\"argumentraw_female_totalFiles:\",argumentraw_female_totalFiles,\"total:(\"+str(arg_imageNeed[change_LHrange][\"Femaleargneed\"])+\") \"+argumentraw_female_datasetPath)\n",
    "        # Load and preprocess a sample image\n",
    "        img_path = os.path.join(extractraw_datasetPath, random_femalefile)#\"picture/3_0_0_20161219154705684.jpg.jpg\"\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(200, 200))\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #i = 0\n",
    "        #Pick a random number from the list\n",
    "        # Generate augmented images and save them\n",
    "        current_iter += 1  \n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=argumentraw_female_datasetPath, save_prefix=random_femalefile, save_format='jpeg'):\n",
    "                #i += 1\n",
    "                #if i % 1 == 0:  # Generate 1 augmented images\n",
    "            break # break the generation loop\n",
    "        #(50-1):\n",
    "        if argumentraw_female_totalFiles>=((arg_imageNeed[change_LHrange][\"Femaleargneed\"])-1):\n",
    "            print(\"Value reached \"+str((arg_imageNeed[change_LHrange][\"Femaleargneed\"])) +\" Exiting loop.\")\n",
    "            break  # Exit the loop\n",
    "\n",
    "    change_LHrange+=1\n",
    "    print(\"Loop ended.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #6**: combine all the dataset to  UTKFace_completeRawDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) combine the UTKFace_argumentRawDataset to  UTKFace_completeRawDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "completeTrain_datasetPath =  \"dataset//UTKFace_completeTrainDataset/\"\n",
    "# Create the destination folder if it doesn't exist\n",
    "if not os.path.exists(completeTrain_datasetPath):\n",
    "    os.makedirs(completeTrain_datasetPath)\n",
    "\n",
    "for root, dirs, files in os.walk(argumentraw_datasetPath):\n",
    "    for file in files:\n",
    "        src_path = os.path.join(root, file)\n",
    "        target_path = os.path.join(completeTrain_datasetPath, file)\n",
    "        shutil.copy(src_path, target_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) combine the UTKFace_extractRawDataset to  UTKFace_completeRawDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to copy files from source folders to destination folder\n",
    "def copy_files(source_folder, destination_folder):\n",
    "    for filename in os.listdir(source_folder):\n",
    "        source_file = os.path.join(source_folder, filename)\n",
    "        destination_file = os.path.join(destination_folder, filename)\n",
    "        shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(train_dirPath, completeTrain_datasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkkkk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step #7**: save detail in in summaryfile in  xlsx file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "# Generating writer engine\n",
    "writer = pd.ExcelWriter(summary_filepath, engine='openpyxl')\n",
    "\n",
    "# Add a plot image to the worksheet\n",
    "img = Image((figure_dirPath+\"/gender_Distribution_of_UTKFace_rawdataset.png\"))  # Replace 'your_plot.png' with the path to your plot image\n",
    "sheet.add_image(img, 'A1')     # Add the image to cell A1\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(summary_filepath)  # Save the Excel file as 'output.xlsx'\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding dataframes to Excel as new sheets\n",
    "#architecture_df.to_excel(writer, sheet_name='cnn_architecture', index=False)\n",
    "#history_df.to_excel(writer, sheet_name='training_log', index=True,index_label='Epoch')\n",
    "# Saving changes and closing writer\n",
    "writer.book.save(summary_filepath)#\"modelsummary.xlsx\")\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
